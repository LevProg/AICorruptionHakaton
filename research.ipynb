{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "research.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "laWkUlgcSwpJ"
      },
      "source": [
        "!pip install python-docx\n",
        "!pip install catboost"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9bIVTtcS1ix"
      },
      "source": [
        "!gdown --id 1zJnmnqJ7uIJz2FNjWYgXbihtx6vT-DH5# Loading a dataset\n",
        "!7z x DataSet_Razmetra.7z -oDataSet_Razmetra# Unpacking the dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1j-SsW59S2-_"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import glob\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from docx import Document\n",
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from catboost import CatBoostClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsxvHiBkS-so"
      },
      "source": [
        "file_names = glob.glob('DataSet_Razmetra/**/**/**/**/Edition_Text.docx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgHjocadTCFw"
      },
      "source": [
        "res = []\n",
        "for f_name in file_names:\n",
        "    res.append(f_name.split('/')[2])\n",
        "\n",
        "pd.Series(res).value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofEA5B97TueX"
      },
      "source": [
        "# we look at the metrics separately for each corruption factor\n",
        "# a dataset for training is formed from marked files, in which a corruption factor was detected\n",
        "# and fixed files\n",
        "# the dataset is divided into train and validation\n",
        "# get TF-IDF from texts\n",
        "# train boosting on these vectors\n",
        "# look at metrics\n",
        "\n",
        "for corr_fac in list(pd.Series(res).unique()):\n",
        "    file_names = glob.glob('DataSet_Razmetra/**/**/**/**/Edition_Text.docx')\n",
        "\n",
        "    parags = []\n",
        "    labels = []\n",
        "\n",
        "    highlighted_cnt = 0\n",
        "\n",
        "    for f_name in tqdm(file_names):\n",
        "        if f_name.split('/')[2]==corr_fac:\n",
        "            try:\n",
        "                doc = Document(f_name)\n",
        "\n",
        "                # check that the text is marked up\n",
        "                for paragraph in doc.paragraphs:\n",
        "                    is_highlighted_text = False\n",
        "\n",
        "                    for run in paragraph.runs:\n",
        "                        if not (run.font.highlight_color == None):\n",
        "                            is_highlighted_text = True\n",
        "                            break\n",
        "\n",
        "                    if is_highlighted_text:\n",
        "                        break\n",
        "\n",
        "                # if the text is marked up, we parse it into paragraphs\n",
        "                if is_highlighted_text:\n",
        "                    highlighted_cnt = highlighted_cnt + 1\n",
        "\n",
        "                    for paragraph in doc.paragraphs:\n",
        "                        if paragraph.text != '': \n",
        "                            is_highlighted_parag = False\n",
        "                            for run in paragraph.runs:\n",
        "                                if not (run.font.highlight_color == None):\n",
        "                                    is_highlighted_parag = True\n",
        "                                    break\n",
        "                            if is_highlighted_parag:\n",
        "                                parags.append(paragraph.text)\n",
        "                                labels.append(f_name.split('/')[2])\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "    print('Найдено', len(file_names), 'файлов, из них', highlighted_cnt, 'с разметкой')\n",
        "\n",
        "    file_names = glob.glob('DataSet_Razmetra/**/**/**/**/NC_Edition_Text.docx')\n",
        "\n",
        "    highlighted_cnt = 0\n",
        "\n",
        "    for f_name in tqdm(file_names):\n",
        "        if f_name.split('/')[2]==corr_fac:\n",
        "            try:\n",
        "                doc = Document(f_name)\n",
        "                for paragraph in doc.paragraphs:\n",
        "                    is_highlighted_text = False\n",
        "                    for run in paragraph.runs:\n",
        "                        if not (run.font.highlight_color == None):\n",
        "                            is_highlighted_text = True\n",
        "                            break\n",
        "                    if is_highlighted_text:\n",
        "                        break\n",
        "                if is_highlighted_text:\n",
        "                    highlighted_cnt = highlighted_cnt + 1\n",
        "                    for paragraph in doc.paragraphs:\n",
        "                        if paragraph.text != '': \n",
        "                            is_highlighted_parag = False\n",
        "                            for run in paragraph.runs:\n",
        "                                if not (run.font.highlight_color == None):\n",
        "                                    is_highlighted_parag = True\n",
        "                                    break\n",
        "                            if is_highlighted_parag:\n",
        "                                parags.append(paragraph.text)\n",
        "                                labels.append('None')\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "    print('Найдено', len(file_names), 'файлов, из них', highlighted_cnt, 'с разметкой')\n",
        "    print(len(parags), len(labels))\n",
        "    \n",
        "    parags_1 = parags[:len(parags)//2]\n",
        "    parags_2 = parags[len(parags)//2:]\n",
        "    labels_1 = labels[:len(labels)//2]\n",
        "    labels_2 = labels[len(labels)//2:]\n",
        "\n",
        "    train_x = parags_1[:int(0.75*len(parags_1))] + parags_2[:int(0.75*len(parags_2))]\n",
        "    train_y = labels_1[:int(0.75*len(labels_1))] + labels_2[:int(0.75*len(labels_2))]\n",
        "    test_x = parags_1[int(0.75*len(parags_1)):] + parags_2[int(0.75*len(parags_2)):]\n",
        "    test_y = labels_1[int(0.75*len(labels_1)):] + labels_2[int(0.75*len(labels_2)):]\n",
        "    len(train_x), len(train_y), len(test_x), len(test_y)\n",
        "\n",
        "    data_train = pd.DataFrame({'parag': train_x,\n",
        "                              'label': train_y}).drop_duplicates()\n",
        "\n",
        "    data_test = pd.DataFrame({'parag': test_x,\n",
        "                              'label': test_y}).drop_duplicates()\n",
        "\n",
        "    vectorizer = TfidfVectorizer(min_df=5, max_df=100000, ngram_range=(1,5))\n",
        "    features_train = vectorizer.fit_transform(data_train.parag)\n",
        "    print(features_train.shape)\n",
        "\n",
        "    features_test = vectorizer.transform(data_test.parag)\n",
        "\n",
        "    clf = CatBoostClassifier(n_estimators=100,\n",
        "                            eval_metric='F1')\n",
        "    clf.fit(features_train, data_train.label, \n",
        "            eval_set=(features_test, data_test.label))\n",
        "    y_test_pred = clf.predict(features_test)\n",
        "\n",
        "    print(corr_fac)\n",
        "    print(classification_report(data_test.label, y_test_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AqL0DJ7UhGo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAXJcqfpfH72"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkMDAUxRfH36"
      },
      "source": [
        "# repeat the same for the selected factors\n",
        "# save the models\n",
        "\n",
        "best_fac = ['4_1', '3_9', '3_5', '4_2', '4_3']\n",
        "\n",
        "models = {}\n",
        "\n",
        "for corr_fac in best_fac:\n",
        "    file_names = glob.glob('DataSet_Razmetra/**/**/**/**/Edition_Text.docx')\n",
        "\n",
        "    parags = []\n",
        "    labels = []\n",
        "\n",
        "    highlighted_cnt = 0\n",
        "\n",
        "    for f_name in tqdm(file_names):\n",
        "        if f_name.split('/')[2]==corr_fac:\n",
        "            try:\n",
        "                doc = Document(f_name)\n",
        "                for paragraph in doc.paragraphs:\n",
        "                    is_highlighted_text = False\n",
        "\n",
        "                    for run in paragraph.runs:\n",
        "                        if not (run.font.highlight_color == None):\n",
        "                            is_highlighted_text = True\n",
        "                            break\n",
        "\n",
        "                    if is_highlighted_text:\n",
        "                        break\n",
        "                if is_highlighted_text:\n",
        "                    highlighted_cnt = highlighted_cnt + 1\n",
        "\n",
        "                    for paragraph in doc.paragraphs:\n",
        "                        if paragraph.text != '': \n",
        "                            is_highlighted_parag = False\n",
        "                            for run in paragraph.runs:\n",
        "                                if not (run.font.highlight_color == None):\n",
        "                                    is_highlighted_parag = True\n",
        "                                    break\n",
        "                            if is_highlighted_parag:\n",
        "                                parags.append(paragraph.text)\n",
        "                                labels.append(f_name.split('/')[2])\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "    print('Найдено', len(file_names), 'файлов, из них', highlighted_cnt, 'с разметкой')\n",
        "\n",
        "    file_names = glob.glob('DataSet_Razmetra/**/**/**/**/NC_Edition_Text.docx')\n",
        "\n",
        "    highlighted_cnt = 0\n",
        "\n",
        "    for f_name in tqdm(file_names):\n",
        "        if f_name.split('/')[2]==corr_fac:\n",
        "            try:\n",
        "                doc = Document(f_name)\n",
        "                for paragraph in doc.paragraphs:\n",
        "                    is_highlighted_text = False\n",
        "\n",
        "                    for run in paragraph.runs:\n",
        "                        if not (run.font.highlight_color == None):\n",
        "                            is_highlighted_text = True\n",
        "                            break\n",
        "                    if is_highlighted_text:\n",
        "                        break\n",
        "                if is_highlighted_text:\n",
        "                    highlighted_cnt = highlighted_cnt + 1\n",
        "\n",
        "                    for paragraph in doc.paragraphs:\n",
        "                        if paragraph.text != '': \n",
        "                            is_highlighted_parag = False\n",
        "                            for run in paragraph.runs:\n",
        "                                if not (run.font.highlight_color == None):\n",
        "                                    is_highlighted_parag = True\n",
        "                                    break\n",
        "                            if is_highlighted_parag:\n",
        "                                parags.append(paragraph.text)\n",
        "                                labels.append('None')\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "    print('Найдено', len(file_names), 'файлов, из них', highlighted_cnt, 'с разметкой')\n",
        "    print(len(parags), len(labels))\n",
        "    \n",
        "    parags_1 = parags[:len(parags)//2]\n",
        "    parags_2 = parags[len(parags)//2:]\n",
        "    labels_1 = labels[:len(labels)//2]\n",
        "    labels_2 = labels[len(labels)//2:]\n",
        "\n",
        "    train_x = parags_1[:int(0.75*len(parags_1))] + parags_2[:int(0.75*len(parags_2))]\n",
        "    train_y = labels_1[:int(0.75*len(labels_1))] + labels_2[:int(0.75*len(labels_2))]\n",
        "    test_x = parags_1[int(0.75*len(parags_1)):] + parags_2[int(0.75*len(parags_2)):]\n",
        "    test_y = labels_1[int(0.75*len(labels_1)):] + labels_2[int(0.75*len(labels_2)):]\n",
        "    len(train_x), len(train_y), len(test_x), len(test_y)\n",
        "\n",
        "    data_train = pd.DataFrame({'parag': train_x,\n",
        "                              'label': train_y}).drop_duplicates()\n",
        "\n",
        "    data_test = pd.DataFrame({'parag': test_x,\n",
        "                              'label': test_y}).drop_duplicates()\n",
        "\n",
        "    vectorizer = TfidfVectorizer(min_df=5, max_df=100000, ngram_range=(1,5))\n",
        "    features_train = vectorizer.fit_transform(data_train.parag)\n",
        "    print(features_train.shape)\n",
        "\n",
        "    features_test = vectorizer.transform(data_test.parag)\n",
        "\n",
        "    clf = CatBoostClassifier(n_estimators=100,\n",
        "                            eval_metric='F1',)\n",
        "    clf.fit(features_train, data_train.label, \n",
        "            eval_set=(features_test, data_test.label))\n",
        "    y_test_pred = clf.predict(features_test)\n",
        "\n",
        "    models[corr_fac] = (vectorizer, clf)\n",
        "\n",
        "    print(corr_fac)\n",
        "    print(classification_report(data_test.label, y_test_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-P07x09yjlBH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiuYf6ylok3z"
      },
      "source": [
        "import pickle\n",
        "with open('models.pickle', 'wb') as f:\n",
        "    pickle.dump(models, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cn694wEq8NVV"
      },
      "source": [
        "Try predict\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VibLm2fQjWRb"
      },
      "source": [
        "import pickle\n",
        "\n",
        "# models - dictionary of tuples (vectorizer, cat)\n",
        "with open('models.pickle', 'rb') as f:\n",
        "    models = pickle.load(f)\n",
        "\n",
        "best_fac = ['3_9', '3_5', '4_3']\n",
        "TRESHOLD = 0.75\n",
        "\n",
        "f_name = 'DataSet_Razmetra/Республика Коми/3_7/A631C9EF-FA79-4453-BAF2-129A55551695/Edition_7/NC_Edition_Text.docx'\n",
        "doc = Document(f_name)\n",
        "\n",
        "for paragraph in doc.paragraphs:    \n",
        "\n",
        "    indicator = False\n",
        "    # check the paragraph with models\n",
        "    for fac in best_fac:  \n",
        "        par = paragraph.text\n",
        "        vectorizer, clf = models[fac]\n",
        "        if clf.predict_proba(vectorizer.transform([par]))[0][1]>TRESHOLD:\n",
        "            indicator = True\n",
        "            break\n",
        "    # color the text\n",
        "    if indicator:\n",
        "        print(paragraph.text)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}